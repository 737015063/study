关于技术知识具体技术问题：（基础加技能）
          区别、场景、源码、机制、（jvm内存管理调优重要)调优思路（结果导向涉及点一一优化）、如何设计海量xxx、（缓存）原理、注意点、如何xxx（保证可见性）、原则、种类
          http请求过程和原理、tcp特点，如何保证可靠性、aop原理、动态代理和cglib、代理实现原理、spring源码ioc加载过程、字节码编译过程、
          注意点：先回答技术本质再技术细节和编程中的扩展，表达能力 、知识点和扩展点出乎面试管意料；
          
做过的项目要深入，技术原理，为什么要用：（思考项目）
                                    项目熟悉为什么做这个项目、项目架构数据库如何设计、核心模块与如何通信、session放哪状态如何保存、哪些方式与区别，
                                    分布式session如何管理有哪些方案、数据结构与算法、jdk用到的设计模式
                                    
                                    最重要思考：项目重要点如何实现（深入技术原理）、遇到困难、怎么解决、扩展功能如何降低耦合、对某个功能进行优化你怎么设计优化
表达能力，和同事的相处，工作态度，书，代码，博客，项目

评价我的表现，应该增加加强什么技术栈
mysql:简单易用、功能、性能、可靠性

通过对应参数开启功能
物理文件组成：
日志文件：错误日志默认关闭可配置路径名称，flush logs可备份
          二进制日志即bin log  --log-bin指定文件开启，可设置文件大小，针对特定的数据库记录，记录文件绝对路径
          查询日志体积大开启影响性能，可追踪sql性能
          慢查询日志记录时间长的sql
          innodb redo日志 undo保证事务安全

数据文件：.frm文件表结构定义消息
          .MYD myisam引擎表数据
          .MYI MYISAM索引相关信息
          
          .ibd和ibdata存放innodb数据
          
replication相关文件：master.info存在slave记录master信息和日志读取到的位置
                    relay log 存放io线程从master读取到的bin log ，sql线程解析sql并应用
                    relay-log.info记录rela log信息
                    
其他文件：system config file系统配置文件 如[mysqld]参数项
         pid file存放进程id
         socket file
         

逻辑模块组成(两层)：
                  sql layer（很多小模块 ）:权限，sql解析，执行优化计划，query cache
                  storage engine layer 数据存取实现部分
                  
sql layer:初始化模块mysql server启动时的初始化操作如buffer和cache结构、系统变量设定、存储引擎设置、内存空间申请
          核心api模块提供些优化底层操作功能的实现如底层数据结构和算法实现，字符串和数字处理，小文件io，格式化输出，内存管理
          网络交互模块抽象出模块交互的接口api，实现数据接收与发送
          client & server交互协议模块自己的信息交互协议建立在 tcp/ip和socket上
          用户模块登录连接权限控制和授权管理=门卫
          访问控制模块监控用户动作根据授权和约束控制数据的访问，结合用户模块组成权限安全管理
          连接管理&连接线程和线程管理：连接管理模块监听接收请求，转发给线程管理模块线程创建和线程的cache，线程处理请求传递结果
          query解析和转发模块解析语义和语法，进行分类并转发
          query cache模块cache query类的请求根据query hash值，数据变化后失效，读写比例高用处大
          query优化器模块根据语句和统计信息和算法分析优化query请求
          表变更管理模块处理ddl（数据定义语言如create）和dml（数据操作语curd）语句
          表维护模块表状态检查错误修复，优化和分析
          系统状态管理模块将状态信息返回给用户
          表管理器维护.frm文件，一个cache它cache各个表结构信息，tabl级别的锁管理
          日志记录模块记录日志binlog,slow query log等
          复制模块读取mastr binlog与slave io线程交互，slave io线程读取binlog西尔relay log，slave sql线程读取relay log解析成sql运行
          存储引擎接口模块抽象化类实现存储引擎的可插拔

过程分析：初始化模块初始化整个系统-->连接管理模块接手监听tcp/ip和socket启动完成准备接受请求-->请求通过网络交互模块，
          用户模块检查授权，连接管理将请求转发线程管理模块请求连接线程建立连接，检查连接池是否由线程或创建接收请求-->转给解析query模块与转发
          （command不解析直接执行），查询cache模块是否缓存，是直接给线程返回结果给客户端-->query优化器模块 ，如果是dml,ddl交给表变更模块，
          统计，检测，修复，整理则交由表维护模块，复制相关由复制模块处理，状态query由系统状态模块处理-->访问控制检查权限，有由表管理模块请求表获取锁，
          表变更模块更加meta信息提交请求给存储引擎模块-->处理完交由连接线程返回成功或失败或错误信息然后继续等待请求或断开连接-->整个过程数据发生改变
          且开启binlog日志模块会记录变更，以上各个模块依赖核心api模块的内存管理和文件io,字符和数字处理
          
mysql工具

存储引擎：MyIsam表锁定、innodb事务安全支持、数据多版本读取、行锁定通过索引、外键支持不建议由性能消耗

网络层：广域网威胁和局域网内部、网络设备出入口
主机层：拦截未授权用户，安全设置不足
数据库层：访问控制授权管理
sql层 ：利用解析原理和校验漏洞提交非法数据
代码层

权限系统：grant tables,gloal、database、table、column、routine level
访问控制实现原理：先用户模块校验host、username、pwd信息，再访问控制模块解析所需权限去匹配用户权限
                 了解主机来源，了解用户需求要做什么，分配对于权限账号，工作分类
                 
数据备份与恢复：数据丢失恢复，新建环境与迁移恢复
逻辑备份：生成insert语句备份，执行脚本恢复，做恢复测试验证备份是否有效
备份策略根据场景和重要性，和要求指定，时间快慢与数据完整性

数据库应用系统（使用数据库的应用）：数据操作通过数据库提供接口完成，性能到底与哪些地方有关，找出应用系统的性能问题根本原因，给出优化方案
功能初衷为用户提供某种服务满足需求，不合理需求功能是否画蛇添足
 
商业需求对性能影响：(系统应该有什么不应该有什么）
   需求合理性分析：第一、每次产品经理们提出新的项目（功能需求）的时候，应该要求他们同时给出该项目的预 期收益的量化指标，以备项目上先后统计评估投入产出比率； 
               第二、在每次项目进行过程中，应该详细记录所有的资源投入，包括人力投入，硬件设施的投入， 以及其他任何项目相关的资源投入； 
               第三、项目（或者功能需求）上线之后应该及时通过手机相关数据统计出项目的实际收益值，以便 计算投入产出比率的时候使用； 
               第四、技术部门应该尽可能推动设计出一个项目（或者功能需求）的投入产出比率的计算规则。
               项目上线一段时间，通过项目实际收益的统计数据和项目的投入资源量，计算出整个项目的实际投入产出值，公布给参与项目的部门，存放以备后查。
               有了实际的投入产出比率，我们就可以和项目立项之初产品经理们的预期投入产出比率做出比较， 判定出这个项目做的是否值得。
               当积累了较多的项目投入产出比率，我们根据历史数据分析一个项目合理的投入产出比率应该是多少。
               在项目立项初，我们就可以判定出产品经理预期投入产出比率是否合理，项目是否真的有进行的必要。
               拿出数据给看，让他知道功能并不是越多越好， 让他知道有些功能是应该撤下来的，即使撤下该功能可能需要投入不少资源
               利益与业绩冲突，成本投入，技术复杂度的负面影响
               
   功能分析：拿简单的功能来分析一下。 需求：一个论坛帖子总量的统计 附加要求：实时更新
          这个功能容易实现，执行一条 SELECT COUNT(*)的 Query 就可以得到结果了
          确实只需要如此简单的一个 Query 就可以得到结果。如果我们采用不是MyISAM存储引擎（会记录总数），而是使用的 Innodb 的存储引擎，
          试想，帖子的表中有上千万的帖子的时候，执行这条 Query 语句需要多少成本？不可能10秒之内完成次查询
          既然这样查询不行，那我们是不是该专门为这个功能建一个表，就只有一个字段，一条记录，就存放这个统计量，每次有新的帖子产生的时候，
          都将这个值增加1，这样我们每次都只需要查询这个表就可 以得到结果了，这个效率肯定能够满足要求了。
          确实，查询效率肯定能够满足要求，可是如果我们的系 统帖子产生很快，在高峰时期可能每秒就有几十甚至上百个帖子新增操作的时候，
          恐怕这个统计表又要 成为大家的噩梦了。要么因为并发的问题造成统计结果的不准确，要么因为锁资源争用严重造成整体性 能的大幅度下降。
          问题的焦点不应该是实现这个功能的技术细节，而是在于这个功能的附加要求“实时更 新”上面。
          当一个论坛的帖子数量很大了之后，到底有多少人会关注这个统计数据是否是实时变化的？ 
          只要去掉了这个“实时更新”的附加条件，我们就可以非常容易的实现这个功能了。就像之前所提 到的那样，通过创建一个统计表，
          然后通过一个定时任务每隔一定时间段去更新一次里面的统计值，这 样既可以解决统计值查询的效率问题，又可以保证不影响新发贴的效率，一举两得。
          在我们应用的系统中还有很多类似的功能点可以优化。分析出那些可以不实时和不完全精确的地方，作出一些相应的折中调整，会给大家带来巨大性能提升。
          如某些场合的列表页面参与列 表的数据量达到一个数量级之后，完全可以不用准确的显示这个列表总共有多少条信息，总共分了多少
          页，而只需要一个大概的估计值或者一个时间段之前的统计值。这样就省略了我们的分页程序需要在分 以前实时 COUNT 出满足条件的记录数。
   功能下线机制：无用功能堆积使系统过度复杂影响整体性能
             很多时候，为系统增加某个功能可能并不需要花费太多的成本，而要想将一个已经运行了一段时间的功能从原有系统中撤下来却是非常困难的。
             对于开发部门，可能要重新整理很多的代码，找出可能存在与增加该功能所编写的代码有交 集的其他功能点，删除没有关联的代码，修改有关联的代码；
             对于测试部门，由于功能的变动，必须要回归测试所有相关的功能点是否正常。可能由于界定困难，不得不将回归范围扩展到很大，测试工作量也很大。
             最后，所有与撤除下线某个功能相关的工作参与者来说，又无法带来任何实质性的收益，而恰恰相 反是，带来的只可能是风险。
             由于上面的这几个因素，可能很少有公司能够有很完善的项目（或者功能）下线机制，也很少有公 司能做到及时将系统中某些不合适的功能下线。
             我们所面对的应用系统总是越来越复杂庞大，短期内的复杂可能并无太大问题，但是随着时间的积累，我们所面对的系统就会变得极其臃肿。
             不仅维护困难，性能也会越来越差。尤其是有些并不合理的功能，在设计之初或者是刚上线的时候 由于数据量较小，带来不了多少性能损耗。
             可随着时间的推移，数据库中的数据量越来越大，数据检索 越来越困难，对真个系统带来的资源消耗也就越来越大。
             系统复杂度给后续功能的开发带来实现的复杂度，本来简单功能，因为系统的复杂而增加很多的逻辑判断，造成系统应用程序的计算量增加，性能会受到影响。
             而如果这些逻辑判断还需要与数据库交互通过持久化的数据来完成的话，所带来的 性能损失就更大，对整个系统的性能影响也就更大了。

系统架构及实现性能影响:
   一个应用系统，Web程序（Web App）和应用程序服务器web server:tomcat,机器)。web server是使用成熟产品，能做的是通过一些简单的参数设置调整来进行调优，
   Web App是根据业务需求自行开发，可控性要好很多。所以从Web应用程序着手分析一个应用程序架构的不同设计对整个系统性能的影响
   系统架构决定了我们系统的构建环境。像建房子一样，清楚房子用途后，会先有建筑设计师来画出基本的造型图，然后还需要结构设计师为我们设计出结构图。
   系统架构设计的过程就和结构工程设计结构图一样，为整个系统搭建出一个尽可能最优的框架，让整个系统能够有一个稳定高效的结构体系让我们实现各种商业需求。
   考虑数据层面相关的架构：
       我们数据库中存放的数据都适合在数据库中存放的吗？大文本、流水队列数据不适合，是否错误的使用了数据库的很多并不是太擅长或者对性能影响很大的功能，
       利用缓存机制cache活跃数据和很少变化的数据：
          1. 系统各种配置及规则数据；配置信息变动的频率非常低，访问概率又很高，适合使用Cache； 
          2. 活跃用户的基本信息数据；很少有用户每天没事干去将自己的基本信息改来改去。且用户的基本信息在应用系统中的访问频率极其频繁。
          3. 活跃用户的个性化定制信息数据；对 Cache 技术的合理利用和扩充造就了项目整体的成功。
          4. 准实时的统计信息数据；就是基于时间段的统计数据。这种数据不会实时更新，当达到重新 Build 该统计数据的时候需要做一次全量更新操作。
          5. 其他一些访问频繁但变更较少的数据；各种系统环境中还会有各种各样的变更较少但是访问很频繁的数据。我们都可以将对他们的访问从数据库移到Cach中。
       我们的数据层实现都是最精简的吗？：
          合理的数据存取实现和拙劣的实现相比，在性能方面的差异会很大。分析一个非常简单且经常会遇到类似情况的示例
          对两个方案做一下简单的比较： 
          一：SELECT id,subject,url FROM photo WHERE user_id = ? limit 10
             再循环十次SELECT COUNT(*) FROM photo_comment WHERE photh_id = ?
          二：SELECT id,subject,url FROM photo WHERE user_id = ? limit 10拼装10个photo的id，
             再in查询SELECT photo_id,count(*) FROM photo_comment WHERE photo_id in (?) GROUP BY photo_id
              1、从 MySQL 执行的 SQL 数量看 ，第一种解决方案为 11（1+10=11）条 SQL 语句，第二种解决方案 为 2 条 SQL 语句（1+1）;
              2、从应用程序与数据库交互看，第一种为 11 次，第二种为 2 次； 
              3、从数据库的IO操作看，简单假设每次SQL为1 个IO，第一种最少11次 IO，第二种小于等于11 次 IO，只有当数据非常之离散情况下才需要11 次；
              4、从数据库处理的查询复杂度来看，第一种为两类很简单的查询，第二种有一条 SQL 语句有 GROUP BY 操作，比第一种解决方案增加了了排序分组操作；
              5、从应用程序结果集处理来看，第一种11次结果集的处理，第二中2次结果集的处理，但是第二种 解决方案中第二词结果处理数量是第一次的 10 倍；
              6、从应用程序数据处理来看，第二种比第一种多了一个拼装 photo_id 的过程。
              我们从6点来做一个性能消耗的分析： 
               1、MySQL对每次提交的SQL都需要进行完全解析，主要消耗资源是数据库主机CPU，第一种方案和第二种方案消耗CP的比例是11:2
               2、应用程序与数据库交互所消耗的资源基本上都在网络方面，同样也是 11：2； 
               3、数据库 IO 操作资源消耗为小于或者等于 1：1； 
               4、第二种解决方案需要比第一种多消耗内存资源进行排序分组操作，消耗由数据量决定可以针对性测试； 
               5、结果集处理次数也为 11：2，但是第二中解决方案第二次处理数量较大，整体来说两次的性能消 耗区别不大；
               6、应用程序数据处理方面所多出的这个photo_id 的拼装所消耗的资源是非常小。
            以对象为中心的思考方式来解决问题加强优化意识，sql优化，归结为过渡依赖嵌套循环的使用或者过渡弱化SQ语句的功能造成性能消耗过多
            过度依赖数据库SQL语句的功能造成数据库操作效率低下
            一步完成与分步完成的差异分析区别在于交互次数和sql复杂度，减少不必要的访问（非群主的profile信息），减少io操作
            重复执行相同的sql浪费资源
            1、Cache 命中率低下造成数据库访问量的增加，浪费Cache系统硬件资源投入； 
            2、过度依赖面向对象，对系统可扩展性过渡追求，使系统设计将对象拆得离散，使系统多复杂Join语句，MySQL Server优势在处理简单逻辑查询，与其锁定机制有较大关系；
            3、对数据库的过渡依赖，将大量更适合存放于文件系统中的数据存入了数据库中，造成数据库资源的浪费，影响到系统的整体性能，如各种日志信息； 
            4、过度理想化系统的用户体验，使大量非核心业务消耗过多的资源，如大量不需要实时更新的数据做了实时统计计算
query语句对性能的影响：
          数据库瓶颈在磁盘io上 根据统计信息得出执行计划决定消耗
          explain sql产生继续计划
                    id: 1 
                    select_type: PRIMARY 
                    table: user 
                    type: eq_ref
                    possible_keys: PRIMARY 
                    key: PRIMARY 
                    key_len: 4 
                    ref: t.user_id 
                    rows: 1 Extra:
              key:可用的索引
              rows可能涉及的行数
              比较两个解决方案的执行计划，看到第一解决方案需要和user表参与Join的记录数MySQL通过统计数据估算出来是31156，
              是通过user_group表返回的所有满足group_id=1的记录（系统中的实际数据是20000）。
              第二种解决方案的执行计划，user表参与Join的数据就只有20条，两者相差很大，通过分析，第二解决方案应该优于第一种解决方案
              io消耗区别在sorting result，方案的排序过滤数据时间不一样，排序后一个取到20000条，一个20条再去join,io相差500倍
              
schema结构对性能的影响：两个解决方案设计的Schema区别在两点，一个是在group_message表中增加了author字段来存放发帖作者的昵称，
                      与use表的nick_name相对应，另外一个就是将user表和group_message表都分拆成了两个表，关系分别都是一一对应。
                      试想一个（帖子/其他)系统访问最多的页面是？都清楚帖子标题列表页面。而帖子标题列表页面主要信息来自group_message表中，
                      帖子标题后面的作者一般都是通过用户名成（昵称）来展示。一种需要join两个表查，一种冗余单表查，把最频繁的sql的表的大字段和不常
                      访问字段拆分出去减少数据检索提高性能

硬件对性能的影响：
          整体io(包括磁盘):iops数量或每秒io总量吞吐量
          cpu:计算量大，数据集中
          网络:与应用交互传递数据量大
          
          OLTP(在线事务处理)应用：并发大（cpu需强劲），数据多且每次访问数据少离散（iops高，吞吐次要，交互频繁网络要强，且缓存），活跃数据比例小（存缓存）
          OLAP（在线分析处理）应用：数据量大（磁盘容量），并发不多cpu次之，每次检索数据多（io吞吐量大），数据集中，返回给客户端数据少网络次之
          简单实现，不绕弯减少来回交互，业务逻辑设计合理，schema设计合理减少步骤或拆分并行步骤，sql要简单
          需求和架构及业务优化：50%
          schema设计和sql优化：35
          数据库自身：15%
          找到根本症结：商业需求合理化，系统架构最优化，逻辑及schema和sql最简化，硬件理性化  
          
数据库锁定机制：
          保证数据一致性，对并发和性能有影响
          各存储引擎锁定机制不一样因为针对场景优化的
          行级锁，表级锁，页级锁
          行级锁：粒度小获取和释放消耗大容易死锁，资源争用小并发大
          表级锁：和行级相反，非事务的存储引擎
          页级锁：行和表级锁之间 innodb 
          锁定机制建立在只能单个线程假设之上，发现可以多个线程，于是修改实现增加concurrent insert,
          引入引擎发现锁定机制不适用，又修改意识到不可能实现一种适用所有存储引擎的锁定机制，不想因为锁定降低引擎性能打击积极，
          所以允许引擎改变通过接口传递的mysql锁定类型自行决定锁定方式
          读锁定：请求的资源当前没有被写锁定，写锁定等待队列没有更高级的写锁定
          写锁定：锁定队列没有该资源的锁定，且写锁定等待队列没有对该资源的写锁定，读锁定队列也没有该资源的锁定
          共享锁和排它锁
          间隙锁：锁定范围查找内的索引索引键值影响性能，通过索引实现锁定：无法利用索引时会改用表锁定，可能锁定其他非结果集的列因为锁定的是索引范围
          事务隔离级别：串行化（serializable）限制影响当前事务的delete和insert操作
                       可重复读（repeat read）一个事务的两次读取之间读取到了别的事务的insert或delete操作，出现幻读，限制影响当前事务的update操作
                       读提交（read commit）在一个事务的两次读第二次读取到了别的事务提交的update操作，出现不可重复读，
                       读未提交（read uncommitt）：脏读，不可重复读，幻读一个事务读取两次数据间有其他事务进行操作（update or insert or delete）
                    事务未隔离或隔离级别低当前事务的两次读取到的数据不一致因为读取到了其他事务的操作结果
                    innodb的锁定机制和事务管理自动检测死锁让小事务回滚大事务继续
                    
                    两个session update操作同一个表：操作相同数据先操作的在操作期间未提交后操作的会阻塞，提交了阻塞的才会继续
                                                  条件无索引升级为表锁，后操作同一张表的操作会阻塞     
                                                  间隙锁索引会锁住范围，后操作想插入范围内的数据会阻塞
                                                  相同索引和记录会被锁住，后操作同索引的不同数据会阻塞
                                                  库死锁似Java死锁，先session1操作t1,session2操作t2表未提交，再session1操作t2,session2操作t1
                    myisam读写阻塞锁定优化:锁定粒度不可变,尽量减少锁定时间（即sql操作时间要快）
                                  减少大复杂sql，差分成多个简单sql
                                  建立高效索引快速检索信息
                                  存必要的字段，选最优的字段类型
                                  合理设置读写的优先级，读重要设置优先级高，写重要设置写优先级高设置concurrent insert并行插入
                    innodb行级锁优化：粒度小，并发性能高锁消耗大
                                     数据检索通过索引完成，避免升级为表锁
                                     合理设计索引在索引上加锁准确减小锁定范围不影响其他query
                                     减少基于范围检索的条件，避免间隙锁锁定不该锁的记录、
                                     减小事务大小，锁定资源量和时间
                                     降低事务级别减少成本、
                           解决死锁：以同样的顺序访问资源
                                    一次锁定所需资源
                                    容易死锁业务的升级锁定粒度减少死锁
          
          
mysql的query优化：optimizer接收到query parser的sql进行分解分析，换算表达式成常量，简化转换并去掉无用查询条件，结构调整，
                 hint信息，读取对象统计信息分析给出执行计划
                 
                 基本思路（优化io和cpu）：确定要优化的sql:慢SQL，给系统能带来更多收益的，执行频繁的sql容易击垮数据库即并发高的业务
                          定位优化的sql性能瓶颈:sql有什么问题，为什么要优化它，判断是io（访问数据）还是cpu（计算如分组排序）瓶颈
                          优化目标:多少秒内,用优化手段达到性能范围，query实现的系统功能重要，调整其他方面如schema、索引做出让步，反之自己让步
                          具体步骤原则：
                              从explain入手：优化一个sql预先在脑里有一个预定的执行计划，用explain验证和调整
                              用小结果集驱动大结果集：join是嵌套循环，循环次数要少减少io，cpu消耗
                              在索引中完成排序   
                              取需要的列：减少数据传输和网络带宽，第一种算法需要排序的取出排序字段和行指针，排好再去取column，访问两次数据
                                                               第二种取出所有的column按排序字段排好序直接返回，访问一次数据减少随机io
                              使用有效的过滤条件：条件并非越多越好，而是选择最有效的数据访问路径，其他条件等同通过索引且索引的长度越短越好
                              避免复杂join和子查询：减少锁多表，不阻塞其他线程，拆分简单sql锁定资源小，阻塞少减少锁定等待时间不影响整体能力
                              
                              数据库所服务很多Query请求，在高并发系统，牺牲单Quer的短暂响应时间而提高整体处理能力是非常值得的。
                              优化本身就是一门平衡与取舍的艺术，只有懂得取舍，平衡整体，才能让系统更优
                              具体优化方法根据不同的应用场景来具体分析，逐步调整。最有效的优化就是不要实现这个商业需求，坏笑···。
                    表访问方式：◆ Type： 
                                        ◇ all：全表扫描 
                                        ◇ const：读常量，只会有一条记录匹配只需要读一次；
                                        ◇ eq_ref：主键或者唯一键索引来访问；
                                        ◇ fulltext： 
                                        ◇ index：全索引扫描； 
                                        ◇ index_merge：查询中同时使用两个（或更多）索引，然后对索引结果进行 merge 之后再读 取表数据； 
                                        ◇ index_subquery：子查询中的返回结果字段组合是一个索引（或索引组合），不是主键或者唯一索引； 
                                        ◇ rang：索引范围扫描；
                                        ◇ ref：Join 语句中被驱动表索引引用查询；
                                        ◇ ref_or_null：与 ref 的唯一区别就是在使用索引引用查询之外再增加一个空值的查询；
                                        ◇ system：系统表，表中只有一行数据； 
                                        ◇ unique_subquery：子查询中的返回结果字段组合是主键或者唯一约束；
                              ◇ Using filesort：Query包含ORDER BY操作，且无法利用索引完成排序操作的时候，不得不选择相应的排序算法来实现。
                              ◇ Using index：数据只需要在Index即可全部获得而不需要再到表中取数据；
                              ◇ Using index for group-by：数据访问和 Using index 一样，所需数据只需要读取索引即可，当Query中使用GROUP BY或DISTINCT子句的时候，
                                        如果分组字段也在索引中，Extra 中的信息就会是 Using index for group-by； 
                              ◇ Using temporary：MySQL某些操作中必须使用临时表的时候，在Extra中就会出现Using temporary常见于GROUP BY和ORDER BY等操。 
                              ◇ Using where：不能通过索引就可以获取所有需要的数据，则会出现 Using where 信息； 
                              
                              
                              
